# 회귀분석 03 - 변수선택 방법론

---

## 목차

**I. 변수선택과 다중공선성 기초**
1. [변수선택의 개념과 중요성](#1-변수선택과-다중공선성)
2. [다중공선성의 원인과 문제점](#2-다중공선성의-원인과-문제점)
3. [다중공선성 판단 방법](#3-다중공선성-판단-방법)

**II. 회귀모형 변수선택 방법**
1. [모든 가능한 회귀 방법](#4-모든-가능한-회귀-방법)
2. [단계선택법](#5-단계선택법)
3. [추가 변수선택 방법들](#6-추가-변수선택-방법들)

**III. 다중공선성 해결 전략**
1. [변수 선택의 해결방법](#7-변수-선택의-해결방법)
2. [축소추정법과 릿지 회귀](#8-축소추정법과-릿지-회귀)
3. [추가적인 곡류 방지 방법](#9-추가적인-곡류-방지-방법)

---

## I. 변수선택과 다중공선성 기초

### 1. 변수선택의 개념과 중요성

- **변수선택 (Variable Selection)**:
    - 여러 설명변수(독립변수) 중에서 회귀모형에 포함시킬 **최적의 변수 조합을 결정**하는 과정입니다.
    - **목표**: 모형의 예측력을 높이면서도 가능한 한 **간단하고 해석하기 쉬운 모형(Parsimonious Model)**을 선호합니다. (오컴의 면도날 원리)
- **다중공선성 (Multicollinearity)**:
    - 회귀모형에 포함된 **설명변수들 사이에 강한 선형 관계**가 존재하는 현상입니다.
    - 하나의 설명변수가 다른 설명변수(들)의 선형 결합으로 거의 표현될 수 있을 때 발생합니다.
    - **문제점**:
        - 회귀계수 추정치의 **분산이 커져 불안정**해집니다. (표준오차 증가)
        - 회귀계수의 **부호가 예상과 다르게 나타나거나, 통계적으로 유의하지 않게 나올 수 있습니다.** (실제로는 중요한 변수임에도 불구하고)
        - 모형의 **안정성과 신뢰성을 떨어뜨립니다.** (데이터가 약간만 변해도 계수 추정치가 크게 변동)
        - 개별 변수의 영향력을 정확히 파악하기 어렵게 만듭니다.
        - (주의: 다중공선성이 있더라도 모형 전체의 예측력 자체는 높을 수 있습니다.)
- **다중공선성 의심 상황**:
    1. 설명변수들의 **표본 상관행렬에서 상관계수가 매우 높게 (+1 또는 -1에 가깝게) 나타날 때**.
    2. 설명변수를 모형에 **추가하거나 제거할 때, 다른 변수들의 추정된 회귀계수의 크기나 부호가 크게 변할 때**.
    3. 자료(데이터 샘플)를 추가하거나 제거할 때, 추정된 회귀계수의 크기나 부호가 크게 변할 때.
    4. 이론적으로나 경험적으로 중요하다고 생각되는 설명변수에 대한 **가설검정 결과가 유의하지 않게 나타날 때** (해당 변수의 t-값이 작고 p-값이 클 때, 신뢰구간이 매우 넓을 때).
    5. 추정된 회귀계수의 **부호가 과거의 경험이나 이론적인 기대와 상반될 때**.
- **분산팽창인자 (VIF, Variance Inflation Factor)**:
    - 다중공선성의 정도를 측정하는 지표입니다.
    - 각 설명변수 $X_j$에 대해, 해당 변수를 종속변수로 하고 나머지 설명변수들을 독립변수로 하는 보조 회귀모형을 적합합니다.
    - $VIF_j = \frac{1}{1 - R_j^2}$
        - $R_j^2$: 변수 $X_j$를 종속변수로 하고 나머지 설명변수들을 독립변수로 하는 회귀모형의 결정계수.
    - **해석**:
        - $VIF_j = 1$: 해당 변수는 다른 설명변수들과 전혀 상관관계가 없음 (다중공선성 없음).
        - $VIF_j > 1$: 다른 설명변수들과의 상관관계로 인해 해당 회귀계수 추정치의 분산이 $VIF_j$배만큼 증가했음을 의미.
        - **일반적인 기준**:
            - $VIF_j \ge 10$ 이면 심각한 다중공선성이 있다고 판단. (경우에 따라 5를 기준으로 보기도 함)
- **R 사용: 해군병원 자료 예제 (다중공선성 진단)**:
    - 데이터 로드: `hospital <- read.table("c:/data/reg/hospital.txt", header=T)`
    - 회귀모형 적합: `hospital.lm <- lm(Y ~ ., data=hospital)` (모든 변수 사용)
    - `summary(hospital.lm)` 결과:
        - 전체 모형의 R-squared는 매우 높으나 (0.9908), 일부 변수(X1, X2, X4, X5)의 p-값이 유의하지 않게 나옴 (다중공선성 의심).
    - **VIF 계산**:
        - `library(fmsb)` (패키지 필요)
        - `VIF(lm(X1 ~ X2+X3+X4+X5, data=hospital))` 결과: `9597.571` (매우 높음)
        - `VIF(lm(X3 ~ X1+X2+X4+X5, data=hospital))` 결과: `8933.087` (매우 높음)
        - X2, X4, X5의 VIF 값도 계산.
    - **상관행렬 확인**: `cor(hospital[,-6])` (종속변수 Y 제외)
        - X1과 X3의 상관계수가 매우 높음 (0.9999040).
    - **다중공선성 해결 시도 (X1 변수 제거)**:
        - `summary(lm(Y ~ X2+X3+X4+X5, data=hospital))`
            - X1 제거 후, X2, X3, X5 변수가 유의하게 나옴. Adjusted R-squared도 약간 증가.
        - 제거 후 각 변수에 대한 VIF 값 재계산. (전반적으로 VIF 값 감소)

### 2. 다중공선성의 원인과 문제점

- **다중공선성의 원인**:
    - 데이터 수집 시에 발생하는 **오차**나 **노이즈**로 인해 설명변수들 간에 강한 상관관계가 발생할 수 있습니다.
    - **데이터 전처리** 과정에서 발생할 수 있습니다 (예: 변수 변형, 데이터 변형).
    - **모형의 구조** 자체가 다중공선성을 유발할 수 있습니다 (예: 중첩된 변수, 상호작용항).
- **다중공선성의 문제점**:
    - 회귀계수 추정치의 **분산이 커져 불안정**해집니다. (표준오차 증가)
    - 회귀계수의 **부호가 예상과 다르게 나타나거나, 통계적으로 유의하지 않게 나올 수 있습니다.** (실제로는 중요한 변수임에도 불구하고)
    - 모형의 **안정성과 신뢰성을 떨어뜨립니다.** (데이터가 약간만 변해도 계수 추정치가 크게 변동)
    - 개별 변수의 영향력을 정확히 파악하기 어렵게 만듭니다.

### 3. 다중공선성 판단 방법

- **상관행렬 분석**:
    - 설명변수들 간의 상관관계를 분석하여 다중공선성을 진단할 수 있습니다.
    - **상관계수**가 매우 높게 나타나면 다중공선성이 의심됩니다.
- **VIF 계산**:
    - 각 설명변수에 대한 VIF 값을 계산하여 다중공선성을 진단할 수 있습니다.
    - **VIF 값이 매우 높게 나타나면** 다중공선성이 의심됩니다.

## II. 회귀모형 변수선택 방법

### 4. 모든 가능한 회귀 방법

- **모든 가능한 회귀 (All Possible Regressions)**:
    - 모든 가능한 독립변수 조합에 대해 회귀모형을 적합시켜보고, 위에서 언급된 변수선택 기준(Adjusted $R^2$, $C_p$, AIC 등)을 사용하여 최적의 모형을 선택하는 방법입니다.
    - 독립변수의 수가 많아지면($k$가 커지면 $2^k - 1$개의 모형) 계산량이 매우 방대해집니다.
    - **R 사용: Hald 자료 예제**:
        - 데이터 로드: `hald = read.csv("c:/data/reg/hald.csv")`
        - `library(leaps)` 패키지 사용:
            - `all_lm = regsubsets(Y ~ ., data=hald)`: 모든 가능한 회귀 수행.
            - `rs = summary(all_lm)`: 결과 요약.
            - `rs$rsq`, `rs$adjr2`, `rs$cp`: 각 모형의 $R^2$, 수정 $R^2$, $C_p$ 값 확인.
                - 예시 결과에서 $C_p$가 가장 작은 모형 (변수 2개 또는 3개 포함)을 선택할 수 있음.
        - `library(olsrr)` 패키지 사용:
            - `model = lm(Y ~ X1+X2+X3+X4, data=hald)`
            - `ols_step_all_possible(model)`: 모든 가능한 회귀 결과와 관련 통계량들을 테이블 형태로 보여줌.
- **앞으로부터 선택법 (Forward Selection)**:
    - 상수항만 있는 모형에서 시작하여, 기준(예: AIC 최소화, F-검정 p-값 유의)을 가장 크게 개선하는 변수를 하나씩 추가하는 방법입니다.
    - 더 이상 유의미하게 모형을 개선하는 변수가 없을 때 중단합니다.
    - **R 사용: Hald 자료 예제**:
        - `start.lm = lm(Y ~ 1, data=hald)` (상수항만 있는 모형)
        - `full.lm = lm(Y ~ ., data=hald)` (모든 변수 포함 모형)
        - `step(start.lm, scope=list(lower=start.lm, upper=full.lm), direction="forward")`: AIC를 기준으로 단계별 변수 선택.
            - 출력 결과에서 각 단계별로 추가되는 변수와 그때의 AIC 값을 보여줍니다.
            - 최종 선택된 모형: `Y ~ X4 + X1 + X2`
        - `olsrr` 패키지: `ols_step_forward_p(model, details=TRUE)` (p-값 기준)
### 5. 단계선택법

- **뒤로부터 제거법 (Backward Elimination)**:
    - 모든 변수를 포함한 모형에서 시작하여, 기준(예: AIC 최소화, F-검정 p-값 비유의)에 가장 적게 기여하는 변수를 하나씩 제거하는 방법입니다.
    - 더 이상 제거해도 모형이 크게 나빠지지 않거나, 모든 남은 변수가 유의할 때 중단합니다.
    - **R 사용: Hald 자료 예제**:
        - `full.lm = lm(Y ~ ., data=hald)`
        - `step(full.lm, data=hald, direction="backward")`: AIC 기준.
            - 최종 선택된 모형: `Y ~ X1 + X2 + X4` (X3가 먼저 제거됨)
        - `olsrr` 패키지: `ols_step_backward_p(model, details=TRUE)` (p-값 기준)
### 6. 추가 변수선택 방법들

- **단계별 회귀방법 (Stepwise Regression)**:
    - 앞으로부터 선택법과 뒤로부터 제거법을 결합한 방법입니다.
    - 매 단계에서 변수를 추가할지 또는 제거할지를 결정합니다.
    - 새로운 변수가 추가될 때마다, 기존에 포함된 변수들 중 제거할 필요가 있는 변수가 있는지 검토합니다.
    - **R 사용: Hald 자료 예제**:
        - `step(start.lm, scope=list(upper=full.lm), data=hald, direction="both")`: AIC 기준.
            - 최종 선택된 모형: `Y ~ X4 + X1 + X2`
        - `olsrr` 패키지: `ols_step_both_p(model, details=TRUE)` (p-값 기준)

## III. 다중공선성 해결 전략

### 7. 변수 선택의 해결방법

- **변수 선택을 통한 해결**:
    - 다중공선성을 야기하는 변수들 중 하나 또는 일부를 모형에서 제외하는 방법입니다.
    - VIF 값이 높은 변수들 중에서 출제할 변수를 선택하는 기준은 다양합니다.

### 8. 축소추정법과 릿지 회귀

- **릿지 회귀 (Ridge Regression)**:
    - 추정과정에 바이어스를 도입하여 다중공선성 문제를 완화하는 방법입니다.
    - 추정과정에서 변수들의 계수값을 0쪽으로 수축시키는 경향이 있습니다.

### 9. 추가적인 공경성 방지 방법

- **변수 변환과 중심화**:
    - 변수들을 중심화(centering)하거나 표준화(standardization)하여 다중공선성을 완화할 수 있습니다.
    - 상호작용항을 포함하는 모형에서 특히 유용한 방법입니다.

---